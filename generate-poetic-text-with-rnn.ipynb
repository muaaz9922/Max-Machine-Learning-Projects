{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall numpy\n!pip install numpy==1.23.1\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM,Dense,Activation\nfrom tensorflow.keras.optimizers import RMSprop\n\n#NOW download the shakespeare txt file\nfilepath = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n\ntext = open(filepath,'rb').read().decode(encoding='utf-8').lower()\n\ntext = text[300000:800000]\n\ncharacters = sorted(set(text))\n\nchar_to_index = dict((c,i) for i,c in enumerate(characters))\nindex_to_char = dict((i,c) for i,c in enumerate(characters)) \n\nSEQ_LENGTH = 40\nSTEP_SIZE = 3\n\nsentences = []\nnext_characters = []\n\nfor i in range(0,len(text) - SEQ_LENGTH, STEP_SIZE):\n\tsentences.append(text[i: i+SEQ_LENGTH])\n\tnext_characters.append(text[i+SEQ_LENGTH])\n\t\nx = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=np.bool_)\ny = np.zeros((len(sentences),len(characters)), dtype=np.bool_)\n\nfor i, sentence in enumerate(sentences):\n\tfor t, character in enumerate(sentence):\n\t\tx[i,t,char_to_index[character]]=1\n\ty[i,char_to_index[next_characters[i]]]=1\n\n\n#NOW we will take the 2 arrays (x and y) and feed them to a RNN model\n\nmodel = Sequential()\nmodel.add(LSTM(128,input_shape=(SEQ_LENGTH,len(characters))))\nmodel.add(Dense(len(characters)))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy',optimizer='Adam')\n\nmodel.fit(x,y,batch_size=256,epochs=4)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T07:47:47.421686Z","iopub.execute_input":"2024-04-17T07:47:47.422298Z","iopub.status.idle":"2024-04-17T07:53:13.598024Z","shell.execute_reply.started":"2024-04-17T07:47:47.422263Z","shell.execute_reply":"2024-04-17T07:53:13.596866Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/4\n\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 112ms/step - loss: 2.9133\nEpoch 2/4\n\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 113ms/step - loss: 2.2613\nEpoch 3/4\n\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 113ms/step - loss: 2.1232\nEpoch 4/4\n\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 113ms/step - loss: 2.0259\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7a915a2847f0>"},"metadata":{}}]},{"cell_type":"code","source":"#Saving the model\n#model.save('textgenerator.model')\n#-------------\n#NOW load the saved model\n#model = tf.keras.model.load_model('textgenerator.model')\n\n#Now creating a function that predicts\n\ndef sample(preds, temperature=1.0):\n    preds = np.asarray(preds).astype('float64')\n    preds = np.log(preds) / temperature\n    exp_preds = np.exp(preds)\n    preds = exp_preds / np.sum(exp_preds)\n    probas = np.random.multinomial(1,preds,1)\n    return np.argmax(probas)\n\n\n\ndef generate_text(length,temperature):\n    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n    generated = ''\n    sentence = text[start_index: start_index + SEQ_LENGTH]\n    generated += sentence\n    for i in range(length):\n        x = np.zeros((1,SEQ_LENGTH, len(characters)))\n        for t, character in enumerate(sentence):\n            x[0,t,char_to_index[character]] = 1\n        \n        predictions = model.predict(x,verbose=0)[0]\n        next_index = sample(predictions,temperature)\n        next_character = index_to_char[next_index]\n        \n        generated += next_character\n        sentence = sentence[1:] + next_character\n    return generated\n\nprint('--------0.2---------')\nprint(generate_text(300, 0.2))\nprint('--------0.4---------')\nprint(generate_text(300, 0.4))\nprint('--------0.6---------')\nprint(generate_text(300, 0.6))\nprint('--------0.8---------')\nprint(generate_text(300, 0.8))\nprint('---------1----------')\nprint(generate_text(300, 1.0))","metadata":{"execution":{"iopub.status.busy":"2024-04-17T08:11:49.568018Z","iopub.execute_input":"2024-04-17T08:11:49.568429Z","iopub.status.idle":"2024-04-17T08:13:46.373709Z","shell.execute_reply.started":"2024-04-17T08:11:49.568394Z","shell.execute_reply":"2024-04-17T08:13:46.371637Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"--------0.2---------\nmy hand,\nthat i yet know not?\n\nfriar laucer:\nthe pare the sall the ware the seath the manter the seath the sore the sord the here the reather the for the seath the great the will the sore the for the wert the hare the merst the mare the the mant the beat of the manter the reare the beat the hard and the manter the manter and the will the \n--------0.4---------\nt, i'll give thee remedy.\n\njuliet:\no, bith to me the prece on were of the will the erent that the is steed the prace,\nthou the wart of here the for the count\nthe make that the will the roust and my but you har the ere the profice on the beathes and me that for the sters bo more bronger with the hist the will for what dis tay and the pray \n--------0.6---------\nlack'd sight only, nought for approbation grionge with arist that not reath,\nthesh the till be that the dabed patt of arimen sow with apy the hes in that so gand maithy lewand thou bropoon liggrong of the with the shall me sull her, broffor the foren be for thire this this be she dowe be the\nsed the cords dreal of burite, your in pouther \n--------0.8---------\nfull of rubs,\nand that my fortune rubs and way the wosh thazst me erion geies pave math sollos,\nwhalt all the foran on speengr so mincus us so pots! bup for hom quee, lond pratele,\nunttith se see with cown catee the but!\nand the, me coust thy sest me chasp,\nne manteen tremine of gores\nin a this of a paads conteed that lrale bre came the k\n---------1----------\nd,\nbehind the globe, that lights the lowtror\nslo:\n?o heace's fo fo seavth that kincery.\n\nbizhorgy\nay!\nwhime'cs me.\nthat eo hend hore she now of liee ael the rowire that boch alane whull bes mone pripr cloak:\nthaith he rome thas to thy paake;\n\nquee tor slaid, and keng gook in heran nott the makoon e'd came mem or hand in homqurech,\nas migh\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}